# app_chatbot.py (ì •ë¦¬ë³¸)
import os, re, logging
from datetime import datetime
from typing import Optional
from fastapi import FastAPI, Depends, HTTPException, status, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
from sklearn.pipeline import FeatureUnion
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.linear_model import LogisticRegression
import json
try:
    import oracledb
    # Oracle 11g(XE)ë©´ Thick ëª¨ë“œ ê¶Œì¥ â€” Instant Client ê²½ë¡œë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ì§€ì •
    # oracledb.init_oracle_client(lib_dir=r"C:\oracle\instantclient_19_22")
except Exception:
    oracledb = None  # ë°°í¬ í™˜ê²½ì— ë”°ë¼ ë“œë¼ì´ë²„ê°€ ì—†ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ì¥ì¹˜


logging.basicConfig(level=logging.INFO)
log = logging.getLogger("chatbot")
# Set-Location C:\k01_javaexp\sp_workspace\prj3\services\chatbot-api
DB_DSN  = os.environ.get("DB_DSN", "localhost:1521/XE")
DB_USER = os.environ.get("DB_USER", "TWO")
DB_PW   = os.environ.get("DB_PW",   "2222")

def load_intent_responses(locale="ko"):
    if oracledb is None:
        log.warning("[bot] oracledb ëª¨ë“ˆ ì—†ìŒ â†’ DB í…œí”Œë¦¿ ë¡œë“œ ê±´ë„ˆëœ€")
        return {}
    try:
        with oracledb.connect(user=DB_USER, password=DB_PW, dsn=DB_DSN) as conn:
            cur = conn.cursor()
            cur.execute("""
                SELECT INTENT_CODE, MESSAGE, ROUTE, SUGGESTIONS_JSON
                  FROM BOT_INTENT_REPLY
                 WHERE LOCALE = :loc
            """, loc=locale)
            data = {}
            for code, msg, route, sug_json in cur:
                try:
                    suggestions = json.loads(sug_json) if sug_json else None
                except Exception:
                    suggestions = None
                data[code] = {"msg": msg, "route": route, "suggestions": suggestions}
            return data
    except Exception as e:
        log.warning(f"[bot] DBì—ì„œ ë‹µë³€ í…œí”Œë¦¿ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

try:
    from utils_route import strip_route  # ë™ì¼ í´ë”ì—ì„œ ì‹¤í–‰ë  ë•Œ
except ModuleNotFoundError:
    # ë¶€ëª¨ í´ë”ì—ì„œ ì‹¤í–‰í•´ë„ ë™ì‘í•˜ë„ë¡ ê²½ë¡œ ë³´ì •
    import os, sys
    sys.path.append(os.path.dirname(__file__))
    from utils_route import strip_route
# ---------------------
# ì„¤ì • (í™˜ê²½ë³€ìˆ˜)
# ---------------------
BOT_SECRET = os.environ.get("BOT_SECRET", "my-secret")
BOT_THRESHOLD = float(os.environ.get("BOT_THRESHOLD", "0.30"))
ALLOW_ORIGINS = [o.strip() for o in os.environ.get("ALLOW_ORIGINS", "http://localhost:8080").split(",")]

# ---------------------
# CORS/ì•±
# ---------------------
app = FastAPI(title="Chatbot API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOW_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------
# ë³´ì•ˆ: API Key ì˜ì¡´ì„± (Headerë¡œ ë°›ê¸°)
# ---------------------
def require_api_key(x_api_key: Optional[str] = Header(None)):
    if x_api_key != BOT_SECRET:
        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="unauthorized")

# ---------------------
# ì „ì²˜ë¦¬/ëª¨ë¸
# ---------------------
def normalize_text(t: str) -> str:
    t = (t or "").strip()
    t = t.lower()  # ì˜ì–´ ì¸ì‚¿ë§ í•˜ì´/í—¬ë¡œ ë“±ë„ ìºì¹˜
    t = re.sub(r"\s+", " ", t)

    # ìì£¼ í‹€ë¦¬ëŠ” ë„ì–´ì“°ê¸°/ë™ì˜ì–´ ì •ê·œí™”
    synonyms = {
        "í™˜ë¶ˆ  ì •ì±…": "í™˜ë¶ˆ ì •ì±…",
        "ë°˜í’ˆì‹ ì²­": "ë°˜í’ˆ ì‹ ì²­",
        "êµí™˜ ìš”ì²­": "êµí™˜ ì‹ ì²­",
        "ìš´ì†¡ì¥ë²ˆí˜¸": "ìš´ì†¡ì¥ ë²ˆí˜¸",
        "ì • ì‚¬ì´ì¦ˆ": "ì •ì‚¬ì´ì¦ˆ",
        "ì¹´ë“œì·¨ì†Œ": "ì¹´ë“œ ì·¨ì†Œ",
    }
    for src, tgt in synonyms.items():
        t = t.replace(src, tgt)
    return t

# â€”â€” (1) ë°ì´í„° ì›ë¬¸
X_train = [
    "ì•ˆë…•","ì•ˆë…•í•˜ì„¸ìš”","ë°˜ê°€ì›Œ","ì¢‹ì€ ì•„ì¹¨",
    "í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜","ëª‡ ì‹œì•¼?","ì§€ê¸ˆ ëª‡ ì‹œì…ë‹ˆê¹Œ","ì‹œê°„ ì¢€ ì•Œë ¤ì¤„ë˜?",
    "ê³ ë§ˆì›Œ","ê°ì‚¬í•©ë‹ˆë‹¤","ê³ ë§™ìŠµë‹ˆë‹¤",
    "ì£¼ë¬¸ ì¡°íšŒ","ë‚´ ì£¼ë¬¸ ìƒíƒœ ì•Œë ¤ì¤˜","ë°°ì†¡ ì–´ë””ì•¼","ìš´ì†¡ì¥ ë²ˆí˜¸ ì•Œë ¤ì¤˜",
    "ë°˜í’ˆ ì‹ ì²­í•˜ê³  ì‹¶ì–´ìš”","êµí™˜ ìš”ì²­","ìƒí’ˆ ì·¨ì†Œí•˜ê³  ì‹¶ì–´ìš”","ìˆ˜ê±° ì¼ì • ë³€ê²½",
    "ì‚¬ì´ì¦ˆ ì¶”ì²œ","ì‚¬ì´ì¦ˆ ê°€ì´ë“œ","ì •ì‚¬ì´ì¦ˆì¸ê°€ìš”",
    "í™˜ë¶ˆ ì–¸ì œ ë˜ë‚˜ìš”","í™˜ë¶ˆ ì •ì±… ì•Œë ¤ì¤˜",
    "ì¿ í° ì‚¬ìš© ë°©ë²•","ì ë¦½ê¸ˆ ì‚¬ìš©","í¬ì¸íŠ¸ í™•ì¸",
]
y_train = [
    "ì¸ì‚¬","ì¸ì‚¬","ì¸ì‚¬","ì¸ì‚¬",
    "ì‹œê°„","ì‹œê°„","ì‹œê°„","ì‹œê°„",
    "ê°ì‚¬","ê°ì‚¬","ê°ì‚¬",
    "ì£¼ë¬¸_ì¡°íšŒ","ì£¼ë¬¸_ì¡°íšŒ","ì£¼ë¬¸_ì¡°íšŒ","ì£¼ë¬¸_ì¡°íšŒ",
    "ë°˜í’ˆ_ì‹ ì²­","êµí™˜_ì‹ ì²­","ì·¨ì†Œ_ì‹ ì²­","ìˆ˜ê±°_ë³€ê²½",
    "ì‚¬ì´ì¦ˆ","ì‚¬ì´ì¦ˆ","ì‚¬ì´ì¦ˆ",
    "í™˜ë¶ˆ","í™˜ë¶ˆ",
    "í˜œíƒ","í˜œíƒ","í˜œíƒ",
]

# â€”â€” (2) ì •ê·œí™”
X_train_norm = [normalize_text(x) for x in X_train]

# â€”â€” (3) íŠ¹ì§• í•˜ì´ë¸Œë¦¬ë“œ: ë¬¸ì n-gram + ë‹¨ì–´ n-gram
char_vec  = TfidfVectorizer(analyzer="char", ngram_range=(2, 5), min_df=1)
word_vec  = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b", ngram_range=(1, 2))
features  = FeatureUnion([("char", char_vec), ("word", word_vec)])

X_vec = features.fit_transform(X_train_norm)
# ë¼ë²¨ë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
from collections import Counter
min_count = min(Counter(y_train).values())

if min_count >= 2:
    # SVM + í™•ë¥ ë³´ì • (êµì°¨ê²€ì¦ í´ë“œ ìˆ˜ë¥¼ ì•ˆì „í•˜ê²Œ ì¶•ì†Œ)
    base_clf = LinearSVC()
    safe_cv = max(2, min(3, min_count))  # 2~3 ì‚¬ì´ì—ì„œ ìµœì†Œìƒ˜í”Œ ìˆ˜ì— ë§ì¶° ì„ íƒ
    model = CalibratedClassifierCV(base_clf, method="sigmoid", cv=safe_cv)
    model.fit(X_vec, y_train)
else:
    # í´ë˜ìŠ¤ê°€ 1ìƒ˜í”Œì¸ ê²ƒì´ ìˆì–´ì„œ CV ë¶ˆê°€ â†’ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ í´ë°±
    model = LogisticRegression(max_iter=1000, multi_class="auto")
    model.fit(X_vec, y_train)


# â€”â€” (5) í‚¤ì›Œë“œ ë£°(ê³ ì‹ ë¢° ìš°ì„  ë§¤ì¹­)
KEYWORD_RULES = [
    (re.compile(r"(ì•ˆë…•|ë°˜ê°€|hello|hi|ã…ã…‡|í•˜ì´)"), "ì¸ì‚¬"),
    (re.compile(r"(ëª‡\s*ì‹œ|í˜„ì¬\s*ì‹œ(ê°„|ê°)|ì§€ê¸ˆ\s*ëª‡\s*ì‹œ)"), "ì‹œê°„"),
    (re.compile(r"(ì£¼ë¬¸|ì£¼ë¬¸\s*ì¡°íšŒ|ë°°ì†¡|ìš´ì†¡ì¥|ì¶œê³ )"), "ì£¼ë¬¸_ì¡°íšŒ"),
    (re.compile(r"(ë°˜í’ˆ|íšŒìˆ˜|ìˆ˜ê±°\s*ìš”ì²­|ìˆ˜ê±°\s*ì‹ ì²­)"), "ë°˜í’ˆ_ì‹ ì²­"),
    (re.compile(r"(êµí™˜)"), "êµí™˜_ì‹ ì²­"),
    (re.compile(r"(ì·¨ì†Œ)"), "ì·¨ì†Œ_ì‹ ì²­"),
    (re.compile(r"(ìˆ˜ê±°).*(ë³€ê²½|ì˜ˆì•½|ì¼ì •)"), "ìˆ˜ê±°_ë³€ê²½"),
    (re.compile(r"(ì‚¬ì´ì¦ˆ|ì¹˜ìˆ˜|í¬ê¸°|ì •ì‚¬ì´ì¦ˆ|ì‘ë‚˜ìš”|í¬ë‚˜ìš”)"), "ì‚¬ì´ì¦ˆ"),
    (re.compile(r"(í™˜ë¶ˆ|ì¹´ë“œ.?ì·¨ì†Œ|í™˜ê¸‰)"), "í™˜ë¶ˆ"),
    (re.compile(r"(ì¿ í°|ì ë¦½ê¸ˆ|í¬ì¸íŠ¸|í• ì¸)"), "í˜œíƒ"),
    (re.compile(r"(ê³ ë§ˆì›Œ|ê°ì‚¬|thanks?)"), "ê°ì‚¬"),
]

# (ì„ íƒ) ë¼ë²¨ë³„ ì„ê³„ì¹˜ ë¯¸ì„¸ì¡°ì •
LABEL_THRESH = {
    "ì¸ì‚¬": 0.35, "ê°ì‚¬": 0.4, "ì‹œê°„": 0.5,  # ì§§ì€ í‘œí˜„ì€ ë‚®ê²Œ
    # ë‚˜ë¨¸ì§€ëŠ” ì „ì—­ BOT_THRESHOLD ì‚¬ìš©
}
# ì‚¬ëŒ ì±„íŒ… í…œí”Œë¦¿
INTENT_RESPONSES = {
    "ì£¼ë¬¸_ì¡°íšŒ": {
        "msg": "ì£¼ë¬¸ ì¡°íšŒëŠ” ë§ˆì´í˜ì´ì§€ > ì£¼ë¬¸/ë°°ì†¡ ì¡°íšŒì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”. ì£¼ë¬¸ë²ˆí˜¸ë¡œ ê²€ìƒ‰ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "route": "order.lookup",
        "suggestions": ["ë°˜í’ˆ ì‹ ì²­", "êµí™˜ ì‹ ì²­", "í™˜ë¶ˆ ì•ˆë‚´"]
    },
    "ë°˜í’ˆ_ì‹ ì²­": {
        "msg": "ë°˜í’ˆì€ ì£¼ë¬¸ ìƒì„¸ í™”ë©´ì˜ [ë°˜í’ˆ ì‹ ì²­] ë²„íŠ¼ìœ¼ë¡œ ì ‘ìˆ˜í•´ ì£¼ì„¸ìš”. ìˆ˜ê±° ì£¼ì†Œì™€ ì‚¬ìœ ë¥¼ ì„ íƒí•˜ì‹œë©´ ë©ë‹ˆë‹¤.",
        "route": "after_sales.return.create",
        "suggestions": ["ìˆ˜ê±° ì¼ì • ë³€ê²½", "í™˜ë¶ˆ ì•ˆë‚´", "êµí™˜ ì‹ ì²­"]
    },
    "êµí™˜_ì‹ ì²­": {
        "msg": "êµí™˜ì€ ì£¼ë¬¸ ìƒì„¸ > [êµí™˜ ì‹ ì²­]ì—ì„œ ì§„í–‰ë¼ìš”. ì‚¬ì´ì¦ˆ/ìƒ‰ìƒ ì„ íƒ í›„ íƒë°° ìˆ˜ê±°ë¥¼ ì˜ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "route": "after_sales.exchange.create",
        "suggestions": ["ì£¼ë¬¸ ì¡°íšŒ", "ìˆ˜ê±° ì¼ì • ë³€ê²½", "ë°˜í’ˆ ì‹ ì²­"]
    },
    "ì·¨ì†Œ_ì‹ ì²­": {
        "msg": "ì¶œê³  ì „ ì£¼ë¬¸ì€ ì£¼ë¬¸ ìƒì„¸ í™”ë©´ì˜ [ì£¼ë¬¸ ì·¨ì†Œ]ë¡œ ì¦‰ì‹œ ì·¨ì†Œë©ë‹ˆë‹¤. ì¶œê³  í›„ì—ëŠ” ë°˜í’ˆ ì ˆì°¨ë¡œ ì•ˆë‚´ë¼ìš”.",
        "route": "after_sales.cancel.create",
        "suggestions": ["ì£¼ë¬¸ ì¡°íšŒ", "í™˜ë¶ˆ ì•ˆë‚´"]
    },
    "ìˆ˜ê±°_ë³€ê²½": {
        "msg": "ìˆ˜ê±° ì¼ì •ì€ ë§ˆì´í˜ì´ì§€ > ì·¨ì†Œ/ë°˜í’ˆ/êµí™˜ ëª©ë¡ì—ì„œ í•´ë‹¹ ìš”ì²­ì˜ [ì¼ì • ë³€ê²½]ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆì–´ìš”.",
        "route": "after_sales.pickup.reschedule",
        "suggestions": ["ë°˜í’ˆ ì‹ ì²­", "êµí™˜ ì‹ ì²­"]
    },
    "ì‚¬ì´ì¦ˆ": {
        "msg": "í•´ë‹¹ ìƒí’ˆì˜ ì‚¬ì´ì¦ˆ ê°€ì´ë“œëŠ” ìƒí’ˆ ìƒì„¸ì˜ [ì‚¬ì´ì¦ˆ ê°€ì´ë“œ]ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”. ë³´í†µ ì •ì‚¬ì´ì¦ˆ ê¸°ì¤€ì…ë‹ˆë‹¤.",
        "route": "product.size_guide",
        "suggestions": ["ì£¼ë¬¸ ì¡°íšŒ", "êµí™˜ ì‹ ì²­"]
    },
    "í™˜ë¶ˆ": {
        "msg": "í™˜ë¶ˆì€ ë°˜í’ˆ íšŒìˆ˜ ë° ê²€ìˆ˜ ì™„ë£Œ í›„ 2~3ì˜ì—…ì¼ ë‚´ ê²°ì œìˆ˜ë‹¨ìœ¼ë¡œ ìë™ ì²˜ë¦¬ë©ë‹ˆë‹¤. ì¹´ë“œ ì·¨ì†ŒëŠ” ì¹´ë“œì‚¬ ì •ì±…ì— ë”°ë¦…ë‹ˆë‹¤.",
        "route": "policy.refund",
        "suggestions": ["ë°˜í’ˆ ì‹ ì²­", "ì£¼ë¬¸ ì¡°íšŒ"]
    },
    "í˜œíƒ": {
        "msg": "ì¿ í°/ì ë¦½ê¸ˆì€ ê²°ì œ ë‹¨ê³„ì—ì„œ ì ìš©í•  ìˆ˜ ìˆì–´ìš”. ë§ˆì´í˜ì´ì§€ > ì¿ í°í•¨/ì ë¦½ê¸ˆì—ì„œ ë³´ìœ  ë‚´ì—­ì„ í™•ì¸í•˜ì„¸ìš”.",
        "route": "benefit.help",
        "suggestions": ["ì£¼ë¬¸ ì¡°íšŒ", "í™˜ë¶ˆ ì•ˆë‚´"]
    }
}
# == [ì¶”ê°€] ë„ì›€ë§(ëª…ë ¹ì–´) ë©”ì‹œì§€ ìƒì„±ê¸° ==
def build_help_message() -> str:
    lines = []
    lines.append("âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´(í‚¤ì›Œë“œ) ì•ˆë‚´")
    lines.append("")
    lines.append("â€¢ ìƒë‹´ ì „í™˜")
    lines.append("  - 'ìƒë‹´ì›' : ì‚¬ëŒ ìƒë‹´ìœ¼ë¡œ ì „í™˜")
    lines.append("  - 'ë´‡'     : ì±—ë´‡ ëª¨ë“œë¡œ ì „í™˜")
    lines.append("")
    lines.append("  - 'ì‹œê°„' : í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜")
    lines.append("")
    lines.append("  - 'ì£¼ë¬¸ ì¡°íšŒ', 'ë°°ì†¡ ì–´ë””ì•¼', 'ìš´ì†¡ì¥ ë²ˆí˜¸'")
    lines.append("")
    lines.append("  - 'ì·¨ì†Œ ì‹ ì²­', 'ë°˜í’ˆ ì‹ ì²­', 'êµí™˜ ì‹ ì²­', 'ìˆ˜ê±° ì¼ì • ë³€ê²½'")
    lines.append("")
    lines.append("  - 'ì‚¬ì´ì¦ˆ', 'ì •ì‚¬ì´ì¦ˆì¸ê°€ìš”', 'í™˜ë¶ˆ', 'í™˜ë¶ˆ ì •ì±…', 'ì¿ í°', 'ì ë¦½ê¸ˆ', 'í¬ì¸íŠ¸'")
    lines.append("")
    lines.append("ì˜ˆ) 'ë°˜í’ˆ ì‹ ì²­í•˜ê³  ì‹¶ì–´ìš”', 'êµí™˜ ìš”ì²­', 'ì¿ í° ì‚¬ìš© ë°©ë²• ì•Œë ¤ì¤˜'")
    return "\n".join(lines)
DB_RESPONSES = load_intent_responses() or INTENT_RESPONSES

def generate_response(label: str, text: str):
    if label == "ì¸ì‚¬":
        return {"msg": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
    if label == "ì‹œê°„":
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return {"msg": f"í˜„ì¬ ì‹œê°„ì€ {now}ì…ë‹ˆë‹¤."}
    if label == "ê°ì‚¬":
        return {"msg": "ì²œë§Œì—ìš”! ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤ ğŸ˜Š"}

    data = DB_RESPONSES.get(label) or INTENT_RESPONSES.get(label)
    if data:
        return {"msg": data["msg"], "route": data.get("route"), "suggestions": data.get("suggestions")}

    return {"msg": "ì£„ì†¡í•´ìš”, ì•„ì§ ê·¸ê±´ ì˜ ëª°ë¼ìš”."}

def predict_with_conf(text: str):
    t = normalize_text(text)
    # == [ì¶”ê°€] ë„ì›€ë§/ëª…ë ¹ì–´ íŠ¸ë¦¬ê±° ==
    if t in ("ëª…ë ¹ì–´", "ë„ì›€ë§", "/help", "help", "/ëª…ë ¹ì–´"):
        help_msg = build_help_message()
        return "ì‹œìŠ¤í…œ", {"msg": help_msg, "route": "system.help", "suggestions": ["ì£¼ë¬¸ ì¡°íšŒ", "ë°˜í’ˆ ì‹ ì²­", "í™˜ë¶ˆ ì•ˆë‚´", "ìƒë‹´ì›"]}, 1.0
    
    # ì•ˆì „ë§
    if t in ("ë´‡", "bot", "ì±—ë´‡"):
        return "ì‹œìŠ¤í…œ", {"msg":"ë´‡ ëª¨ë“œ ì „í™˜ ìš”ì²­ì…ë‹ˆë‹¤."}, 1.0
    if t in ("ìƒë‹´ì›", "ì‚¬ëŒ", "ìƒë‹´ì‚¬", "ì˜¤í¼ë ˆì´í„°"):
        return "ë¯¸ë§¤ì¹­", {"msg":"ìƒë‹´ì› ì—°ê²°ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."}, 1.0
    if t in ("ì‹œê°„", "í˜„ì¬ ì‹œê°„", "í˜„ì¬ì‹œê°„", "ì‹œê°", "ì§€ê¸ˆ ì‹œê°„", "time"):
        return "ì‹œê°„", {"msg": f"í˜„ì¬ ì‹œê°„ì€ {datetime.now():%Y-%m-%d %H:%M:%S}ì…ë‹ˆë‹¤."}, 0.99

    # ë£°
    for pat, lab in KEYWORD_RULES:
        if pat.search(t):
            return lab, generate_response(lab, t), 0.97

    # ëª¨ë¸
    vec   = features.transform([t])
    lab   = model.predict(vec)[0]
    proba = float(max(model.predict_proba(vec)[0]))

    thr = LABEL_THRESH.get(lab, BOT_THRESHOLD)
    if proba < thr:
        return "ë¯¸ë§¤ì¹­", {"msg":"ìƒë‹´ì› ì—°ê²°ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."}, proba

    return lab, generate_response(lab, t), proba
# ---------------------
# ìŠ¤í‚¤ë§ˆ
# ---------------------
from typing import List, Optional
class InferReq(BaseModel):
    text: str
    sessionId: Optional[str] = "anon"

class InferRes(BaseModel):
    label: str
    reply: str
    confidence: float
    sessionId: str
    route: Optional[str] = None
    suggestions: Optional[List[str]] = None

# ---------------------
# ì—”ë“œí¬ì¸íŠ¸
# ---------------------
@app.get("/healthz")
def health():
    return {"ok": True}

@app.post("/infer", response_model=InferRes, dependencies=[Depends(require_api_key)])
def infer(req: InferReq):
    if not req.text or not req.text.strip():
        raise HTTPException(status_code=400, detail="text is required")

    label, payload, conf = predict_with_conf(req.text)   # payload = {"msg":..., "route":..., "suggestions":[...]}
    reply = payload.get("msg", "...")
    route = payload.get("route")
    suggestions = payload.get("suggestions")

    log.info(f"[infer] sid={req.sessionId} label={label} conf={conf:.3f} text={req.text}")
    return InferRes(
        label=label,
        reply=reply,
        confidence=conf,
        sessionId=req.sessionId,
        route=route,
        suggestions=suggestions
    )